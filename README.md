# ğŸ§  LLM-Powered Chatbot with RAG on Custom Domain (Local Inference)
<img width="829" height="483" alt="image" src="https://github.com/user-attachments/assets/0e4cf32d-d05b-4ae3-bb85-d38430c11329" />

A fully local Retrieval-Augmented Generation (RAG) chatbot built using LangChain and Hugging Face Transformers. It supports question-answering over custom documents without relying on any external API â€” everything runs locally.

---

## âœ… Features

- Upload `.pdf` and `.txt` files as knowledge base
- Chunk and embed documents using `sentence-transformers`
- Perform semantic search with FAISS
- Answer questions using a local LLM (`flan-t5-base`)
- Interactive web interface built with Streamlit

---

## ğŸ—‚ï¸ Project Structure

```bash
rag_chatbot/
â”œâ”€â”€ app.py                  # Main Streamlit app
â”œâ”€â”€ document_loader.py      # Loads and chunks documents
â”œâ”€â”€ vector_store.py         # Handles FAISS vector store
â”œâ”€â”€ qa_chain.py             # Builds the RetrievalQA chain using local LLM
â”œâ”€â”€ docs/                   # Folder for uploaded documents
â”œâ”€â”€ .env                    # For future API support (optional)
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ assets/
    â””â”€â”€ working_demo.png    # Screenshot of the app in action
```
# Step 1: Clone the repository
git clone https://github.com/yourusername/rag_chatbot.git
cd rag_chatbot

# Step 2: Create a virtual environment (recommended)
python -m venv venv
venv\Scripts\activate  # On Windows
# source venv/bin/activate  # On macOS/Linux

# Step 3: Install dependencies

pip install streamlit langchain faiss-cpu sentence-transformers transformers pypdf python-dotenv

# Step 4: Run the Streamlit app
streamlit run app.py


##ğŸ”§ Built With
LangChain

Sentence Transformers

Hugging Face Transformers

FAISS

Streamlit

## ğŸ“„ License
MIT License â€“ feel free to use, modify, and share.




